{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "181ebe5f-8e28-4ff6-8869-0bde213f544a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GLOBAL CLEANUP — suppress all logs, warnings, HF noise\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"torch\").setLevel(logging.ERROR)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f70cb83-7158-4cc6-975f-a51af7a52451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze done in 0.05 min\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BRONZE INGESTION — Raw arXiv JSON → Delta\n",
    "# ============================================================\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "\n",
    "input_path = \"/FileStore/arxiv_raw/unzipped/arxiv-metadata-oai-snapshot.json\"\n",
    "bronze_path = \"/FileStore/delta/arxiv_bronze_v2\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_bronze = (\n",
    "    spark.read\n",
    "         .option(\"multiLine\", True)\n",
    "         .option(\"mode\", \"PERMISSIVE\")\n",
    "         .json(input_path)\n",
    "         .withColumn(\"ingest_ts\", current_timestamp())\n",
    ")\n",
    "\n",
    "(df_bronze.write.format(\"delta\").mode(\"overwrite\").save(bronze_path))\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS arxiv_bronze_v2\n",
    "USING DELTA\n",
    "LOCATION '{bronze_path}'\n",
    "\"\"\")\n",
    "\n",
    "elapsed = (time.time() - start) / 60\n",
    "print(f\"Bronze done in {elapsed:.2f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b95081-e0b1-43eb-9074-5639f7c32e65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver done in 0.12 min\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SILVER LAYER — Cleaned Metadata\n",
    "# ============================================================\n",
    "\n",
    "silver_path = \"/FileStore/delta/arxiv_silver_v2\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_raw = spark.table(\"arxiv_bronze_v2\")\n",
    "\n",
    "df_silver = (\n",
    "    df_raw\n",
    "        .select(\n",
    "            \"id\", \"title\", \"abstract\", \"authors\", \"categories\",\n",
    "            \"update_date\", \"versions\"\n",
    "        )\n",
    "        .withColumn(\"title_clean\", lower(trim(col(\"title\"))))\n",
    "        .withColumn(\"abstract_clean\", lower(trim(col(\"abstract\"))))\n",
    "        .withColumn(\"authors_clean\", lower(trim(col(\"authors\"))))\n",
    "        .withColumn(\"categories_clean\", lower(trim(col(\"categories\"))))\n",
    "        .filter(col(\"abstract_clean\").isNotNull())\n",
    "        .withColumn(\"clean_ts\", current_timestamp())\n",
    ")\n",
    "\n",
    "(df_silver.write.format(\"delta\").mode(\"overwrite\").save(silver_path))\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS arxiv_silver_v2\n",
    "USING DELTA\n",
    "LOCATION '{silver_path}'\n",
    "\"\"\")\n",
    "\n",
    "elapsed = (time.time() - start) / 60\n",
    "print(f\"Silver done in {elapsed:.2f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab4d994c-31df-4123-a0db-b3799226e958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold done in 0.54 min\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# GOLD LAYER — Chunking + Distributed Embeddings (Spark UDF)\n",
    "# ============================================================\n",
    "\n",
    "import time\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "start = time.time()\n",
    "gold_path = \"/FileStore/delta/arxiv_gold_v2\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load Silver table\n",
    "# ------------------------------------------------------------\n",
    "df_silver = spark.table(\"arxiv_silver_v2\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Chunk abstracts into groups of sentences\n",
    "# ------------------------------------------------------------\n",
    "CHUNK_SIZE = 5\n",
    "\n",
    "df_sentences = df_silver.select(\n",
    "    \"id\",\n",
    "    col(\"title_clean\").alias(\"title\"),\n",
    "    col(\"categories_clean\").alias(\"categories\"),\n",
    "    split(\n",
    "        regexp_replace(col(\"abstract_clean\"), r\"\\s+\", \" \"),\n",
    "        r\"(?<=[\\.\\?\\!])\\s+\"\n",
    "    ).alias(\"sentences\")\n",
    ")\n",
    "\n",
    "df_exploded = (\n",
    "    df_sentences\n",
    "        .select(\n",
    "            \"id\", \"title\", \"categories\",\n",
    "            posexplode(\"sentences\").alias(\"sent_idx\", \"sentence\")\n",
    "        )\n",
    "        .filter(col(\"sentence\") != \"\")\n",
    ")\n",
    "\n",
    "df_chunks = (\n",
    "    df_exploded\n",
    "        .withColumn(\"chunk_id\", floor(col(\"sent_idx\") / CHUNK_SIZE))\n",
    "        .groupBy(\"id\", \"title\", \"categories\", \"chunk_id\")\n",
    "        .agg(concat_ws(\" \", collect_list(\"sentence\")).alias(\"chunk_text\"))\n",
    "        .filter(col(\"chunk_text\") != \"\")\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Distributed embedding using Pandas UDF\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Broadcast model name\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "bc_model_name = spark.sparkContext.broadcast(model_name)\n",
    "\n",
    "@pandas_udf(ArrayType(FloatType()))\n",
    "def embed_chunks(batch: pd.Series) -> pd.Series:\n",
    "    # Load model once per worker\n",
    "    model = SentenceTransformer(bc_model_name.value)\n",
    "    embeddings = model.encode(batch.tolist(), show_progress_bar=False)\n",
    "    return pd.Series([list(vec.astype(\"float32\")) for vec in embeddings])\n",
    "\n",
    "# Apply distributed embedding\n",
    "df_gold = df_chunks.withColumn(\"embedding\", embed_chunks(\"chunk_text\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Write Gold Delta table\n",
    "# ------------------------------------------------------------\n",
    "(\n",
    "    df_gold.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(gold_path)\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS arxiv_gold_v2\n",
    "USING DELTA\n",
    "LOCATION '{gold_path}'\n",
    "\"\"\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Print timing\n",
    "# ------------------------------------------------------------\n",
    "elapsed = (time.time() - start) / 60\n",
    "print(f\"Gold done in {elapsed:.2f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d533a105-cbc4-450a-9f0b-84b39f3bb350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcb4675ec3d4c908c8ca1234ec2bd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index setup done in 0.02 min\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DISTRIBUTED NEAREST-NEIGHBOR SEARCH (Spark Pandas UDF)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_gold = (\n",
    "    spark.table(\"arxiv_gold_v2\")\n",
    "         .select(\"chunk_text\", \"embedding\")\n",
    "         .cache()\n",
    ")\n",
    "\n",
    "emb_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_query(q: str) -> np.ndarray:\n",
    "    return emb_model.encode([q], show_progress_bar=False).astype(\"float32\")[0]\n",
    "\n",
    "@pandas_udf(\"float\")\n",
    "def cosine_sim(col: pd.Series) -> pd.Series:\n",
    "    mat = np.stack(col.values).astype(np.float32)\n",
    "    q = cosine_sim.qvec\n",
    "    sims = np.dot(mat, q) / (np.linalg.norm(mat, axis=1) * np.linalg.norm(q))\n",
    "    return pd.Series(sims)\n",
    "\n",
    "def retrieve_spark(query: str, k: int = 5):\n",
    "    qvec = embed_query(query)\n",
    "    cosine_sim.qvec = qvec\n",
    "\n",
    "    df_scored = df_gold.withColumn(\"score\", cosine_sim(\"embedding\"))\n",
    "\n",
    "    topk = (\n",
    "        df_scored.orderBy(F.desc(\"score\"))\n",
    "                 .limit(k)\n",
    "                 .select(\"chunk_text\")\n",
    "                 .toPandas()\n",
    "    )\n",
    "\n",
    "    return [row.chunk_text for row in topk.itertuples()]\n",
    "\n",
    "elapsed = (time.time() - start) / 60\n",
    "print(f\"Index setup done in {elapsed:.2f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44b9c619-99aa-43ea-a61c-07e1c29d6022",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ccc2df0d90482785e8b211fd2e221d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/453 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG setup done in 0.04 min\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# RAG WITH PHI-2 — CLEAN OUTPUT ONLY\n",
    "# ============================================================\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "LLM_MODEL_NAME = \"microsoft/phi-2\"  # example; you can swap this\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(LLM_MODEL_NAME)\n",
    "\n",
    "gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tok,\n",
    "    device=-1,\n",
    "    pad_token_id=tok.eos_token_id\n",
    ")\n",
    "\n",
    "def generate_answer(question: str, k: int = 5, max_new_tokens: int = 256):\n",
    "    chunks = retrieve_spark(question, k=k)\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        [f\"Chunk {i+1}:\\n{c}\" for i, c in enumerate(chunks)]\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a helpful assistant that answers questions using ONLY the provided context.\\n\"\n",
    "        \"If the answer is not in the context, say: 'The context does not contain the answer.'\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "    out = gen(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tok.eos_token_id\n",
    "    )[0][\"generated_text\"]\n",
    "\n",
    "    return out.replace(prompt, \"\").strip()\n",
    "\n",
    "elapsed = (time.time() - start) / 60\n",
    "print(f\"RAG setup done in {elapsed:.2f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "914b3991-fd4d-402b-b609-c31b630eb744",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How are graph neural networks used for molecular property prediction?\nAnswer: Graph neural networks are used for molecular property prediction by taking into account the structure of molecules and their interactions with other molecules. This allows for more accurate predictions of molecular properties, such as solubility and toxicity, which can be useful in drug discovery and other applications.\nAnswered found in 0.85 min\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FINAL CLEAN EXECUTION — ONLY PRINTS QUESTION + ANSWER\n",
    "# ============================================================\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "question = \"How are graph neural networks used for molecular property prediction?\"\n",
    "answer = generate_answer(question, k=5)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "elapsed = (time.time() - start) / 60\n",
    "print(f\"Answered found in {elapsed:.2f} min\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "RAG_BIG_DATA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}